{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''In a country like India with a galloping population, unfortunately nobody is paying attention to the issue \n",
    "of population. Political parties are feeling shy, politicians are feeling shy, Parliament also does not adequately discuss \n",
    "about the issue,” said Naidu while addressing the 58th convocation of Indian Agricultural Research Institute (IARI).\n",
    "\n",
    "He said, “You know how population is growing, creating problems. See the problems in Delhi, traffic, more human beings, \n",
    "more vehicles, more tension, less attention. If you have tension you cannot pay attention.” \n",
    "Emphasising on the need to increase food production to meet demand of growing population, Naidu said, \n",
    "“In future if population increases like this, and you are not able to adequately match it with increase in production, \n",
    "there will be problem'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub(\"[^a-zA-Z]\", ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 53)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21677716, 0.        , 0.        , 0.        , 0.32368731,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.26114888, 0.        , 0.        , 0.26114888,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.32368731,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.43355432, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32368731, 0.        ],\n",
       "       [0.        , 0.20243885, 0.16332639, 0.20243885, 0.20243885,\n",
       "        0.        , 0.        , 0.        , 0.20243885, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20243885, 0.        ,\n",
       "        0.4048777 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20243885, 0.        , 0.        , 0.20243885,\n",
       "        0.20243885, 0.16332639, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16332639, 0.        , 0.        ,\n",
       "        0.20243885, 0.20243885, 0.        , 0.        , 0.20243885,\n",
       "        0.20243885, 0.        , 0.        , 0.        , 0.20243885,\n",
       "        0.13557566, 0.        , 0.4048777 , 0.        , 0.20243885,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.50022157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40357562,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.50022157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33500422, 0.33500422, 0.        , 0.        ,\n",
       "        0.33500422, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2290641 , 0.34203392, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.34203392, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34203392, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34203392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2290641 , 0.        , 0.        ,\n",
       "        0.        , 0.34203392, 0.        , 0.27595081, 0.        ,\n",
       "        0.34203392, 0.        , 0.34203392],\n",
       "       [0.18444605, 0.        , 0.14880991, 0.        , 0.        ,\n",
       "        0.12352567, 0.        , 0.18444605, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18444605, 0.        , 0.18444605,\n",
       "        0.        , 0.18444605, 0.18444605, 0.        , 0.14880991,\n",
       "        0.        , 0.        , 0.55333814, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14880991,\n",
       "        0.18444605, 0.18444605, 0.14880991, 0.18444605, 0.        ,\n",
       "        0.        , 0.        , 0.18444605, 0.        , 0.        ,\n",
       "        0.        , 0.24705134, 0.12352567, 0.36889209, 0.        ,\n",
       "        0.12352567, 0.        , 0.        , 0.14880991, 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.18444605]\n"
     ]
    }
   ],
   "source": [
    "print(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.20243885 0.16332639 0.20243885 0.20243885]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.18444605 0.         0.14880991 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw back of Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the words have given same importance\n",
    "# No Semantic information preserved\n",
    "# For above two problems TF-IDF model is the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps in TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lower case the corpus or paragraph.\n",
    "# 2. Tokenization.\n",
    "# 3. TF: Term Frequency, IDF: Inverse Document Frequency, TF-IDF = TF*log(IDF).\n",
    "# 4. TF = No. of occurance of a word in a document / No. of words in that document.\n",
    "# 5. IDF = log(No. of documents/No. of documents containing the word)\n",
    "# 6. TFIDF(word) = TF(Document, word) * IDF (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''In a country like India with a galloping population, unfortunately nobody is paying attention to the issue \n",
    "of population. Political parties are feeling shy, politicians are feeling shy, Parliament also does not adequately discuss \n",
    "about the issue,” said Naidu while addressing the 58th convocation of Indian Agricultural Research Institute (IARI).\n",
    "\n",
    "He said, “You know how population is growing, creating problems. See the problems in Delhi, traffic, more human beings, \n",
    "more vehicles, more tension, less attention. If you have tension you cannot pay attention.” \n",
    "Emphasising on the need to increase food production to meet demand of growing population, Naidu said, \n",
    "“In future if population increases like this, and you are not able to adequately match it with increase in production, \n",
    "there will be problem'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub(\"[^a-zA-Z]\", ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatung the TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the TF-IDF model\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cv = TfidfVectorizer()\n",
    "# X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21677716, 0.        , 0.        , 0.        , 0.32368731,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.26114888, 0.        , 0.        , 0.26114888,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.32368731,\n",
       "        0.        , 0.        , 0.        , 0.32368731, 0.        ,\n",
       "        0.        , 0.43355432, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32368731, 0.        ],\n",
       "       [0.        , 0.20243885, 0.16332639, 0.20243885, 0.20243885,\n",
       "        0.        , 0.        , 0.        , 0.20243885, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20243885, 0.        ,\n",
       "        0.4048777 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20243885, 0.        , 0.        , 0.20243885,\n",
       "        0.20243885, 0.16332639, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16332639, 0.        , 0.        ,\n",
       "        0.20243885, 0.20243885, 0.        , 0.        , 0.20243885,\n",
       "        0.20243885, 0.        , 0.        , 0.        , 0.20243885,\n",
       "        0.13557566, 0.        , 0.4048777 , 0.        , 0.20243885,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.50022157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.40357562,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.50022157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33500422, 0.33500422, 0.        , 0.        ,\n",
       "        0.33500422, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2290641 , 0.34203392, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.34203392, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.34203392, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34203392, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2290641 , 0.        , 0.        ,\n",
       "        0.        , 0.34203392, 0.        , 0.27595081, 0.        ,\n",
       "        0.34203392, 0.        , 0.34203392],\n",
       "       [0.18444605, 0.        , 0.14880991, 0.        , 0.        ,\n",
       "        0.12352567, 0.        , 0.18444605, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18444605, 0.        , 0.18444605,\n",
       "        0.        , 0.18444605, 0.18444605, 0.        , 0.14880991,\n",
       "        0.        , 0.        , 0.55333814, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14880991,\n",
       "        0.18444605, 0.18444605, 0.14880991, 0.18444605, 0.        ,\n",
       "        0.        , 0.        , 0.18444605, 0.        , 0.        ,\n",
       "        0.        , 0.24705134, 0.12352567, 0.36889209, 0.        ,\n",
       "        0.12352567, 0.        , 0.        , 0.14880991, 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 53)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (4, 0)\t0.18444604729119288\n"
     ]
    }
   ],
   "source": [
    "print(X[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 26)\t0.2611488808945384\n",
      "  (0, 5)\t0.21677716168619507\n",
      "  (0, 38)\t0.3236873066380182\n",
      "  (0, 34)\t0.3236873066380182\n",
      "  (0, 51)\t0.3236873066380182\n",
      "  (0, 41)\t0.43355432337239014\n",
      "  (0, 18)\t0.3236873066380182\n",
      "  (0, 23)\t0.3236873066380182\n",
      "  (0, 29)\t0.2611488808945384\n",
      "  (0, 9)\t0.3236873066380182\n",
      "  (1, 21)\t0.20243884765910772\n",
      "  (1, 25)\t0.20243884765910772\n",
      "  (1, 44)\t0.20243884765910772\n",
      "  (1, 3)\t0.20243884765910772\n",
      "  (1, 24)\t0.20243884765910772\n",
      "  (1, 8)\t0.20243884765910772\n",
      "  (1, 49)\t0.20243884765910772\n",
      "  (1, 1)\t0.20243884765910772\n",
      "  (1, 32)\t0.16332638763273197\n",
      "  (1, 45)\t0.13557565561148596\n",
      "  (1, 13)\t0.20243884765910772\n",
      "  (1, 2)\t0.16332638763273197\n",
      "  (1, 4)\t0.20243884765910772\n",
      "  (1, 35)\t0.20243884765910772\n",
      "  (1, 40)\t0.20243884765910772\n",
      "  :\t:\n",
      "  (3, 11)\t0.3420339209721722\n",
      "  (3, 46)\t0.3420339209721722\n",
      "  (3, 42)\t0.2290641031273583\n",
      "  (3, 5)\t0.2290641031273583\n",
      "  (4, 30)\t0.18444604729119288\n",
      "  (4, 0)\t0.18444604729119288\n",
      "  (4, 17)\t0.18444604729119288\n",
      "  (4, 12)\t0.18444604729119288\n",
      "  (4, 31)\t0.18444604729119288\n",
      "  (4, 43)\t0.36889209458238575\n",
      "  (4, 16)\t0.18444604729119288\n",
      "  (4, 22)\t0.5533381418735785\n",
      "  (4, 33)\t0.18444604729119288\n",
      "  (4, 14)\t0.18444604729119288\n",
      "  (4, 37)\t0.18444604729119288\n",
      "  (4, 7)\t0.18444604729119288\n",
      "  (4, 48)\t0.14880990958778192\n",
      "  (4, 42)\t0.12352566750705657\n",
      "  (4, 19)\t0.14880990958778192\n",
      "  (4, 32)\t0.14880990958778192\n",
      "  (4, 45)\t0.12352566750705657\n",
      "  (4, 2)\t0.14880990958778192\n",
      "  (4, 5)\t0.12352566750705657\n",
      "  (4, 41)\t0.24705133501411314\n",
      "  (4, 29)\t0.14880990958778192\n"
     ]
    }
   ],
   "source": [
    "print(X[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
